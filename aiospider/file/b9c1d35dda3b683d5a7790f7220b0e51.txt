Angela Sheffield, Senior Program Manager for Data Science and Artificial Intelligence Artificial intelligence (AI) is a fascinating concept that has brought us movie villains, chess-playing supercomputers, and most recently, that can manipulate audio and video like never before. But what does something like AI this have to do with nuclear weapons and (NNSA)? Ask Angela Sheffield, an internationally recognized expert in nuclear nonproliferation and applications of AI for national security, who has transformed NNSA’s work on AI within the Office of Defense Nuclear Nonproliferation’s (DNN) Research and Development (R&D) program. Part of DNN’s role in nuclear security is to prevent state and non-state actors across the globe from developing nuclear weapons. In her role as Senior Program Manager for AI and Data Science, Sheffield directs NNSA’s efforts to develop the next generation of AI methods and technologies that will enable the detection of early indicators of illicit nuclear weapons development. These technologies also reveal insights about the sophistication of existing nuclear weapons programs pursued by other nations. Her program office is partnering with the U.S. Department of Defense and the intelligence community to deploy them.While AI advancements are reaching dizzying heights in the private sector, Sheffield recognized a critical shortcoming – the needs of the Nuclear Security Enterprise, and the U.S. government, cannot be met by commercially developed AI. This realization helped her shape the direction of the R&D program’s AI research, and today it drives the demand for next-generation technologies developed by those within the national security world.In honor of Sheffield’s service to the Nation, this week’s celebration of , and the annual observance of Black History Month, we asked her to share her perspective as an NNSA team member. The United States faces pressing nuclear security challenges. From my time in the military, I recognize firsthand the urgency of these challenges and how advances in science and technology can address them. I still maintain that sense of urgency, and it drives my approach to R&D.As an intelligence analyst in the Air I made assessments that informed the decisions of U.S. leaders at the highest level using limited information. Today, as an expert in AI, I know how we can advance the science to develop AI systems that reveal insights to better build such analyses. National security analysts across the government produce assessments every day that inform major U.S. nuclear security policy and decisions – without waiting for our science.While diverse, my career is anchored in science and technology for national security and focused on mathematics and computing. When AI emerged, I saw the opportunity to bring in more tools to address the pressing challenges of nuclear security. This was not based on the “hype” around such a technology, but rather my understanding of the math and the science of nuclear weapons development.That said, seeing the opportunity was not enough. To realize the transformational potential of AI in national security takes strategic vision and a research agenda that leverages the capabilities of the entire Nuclear Security Enterprise.My strategy shares the Manhattan Project’s alignment of R&D to a common, specific goal. Theirs was to advance nuclear science and build an atomic bomb; ours is to advance the science of AI to build capabilities to detect nuclear proliferation.The R&D to achieve this goal is exceptionally hard, complex, and multidisciplinary. It requires the “Team Science” for which the National Laboratories – the enduring legacy of the Manhattan Project – are built. This R&D is too complex for one single project or initiative. It happens over hundreds of separate research efforts across the National Laboratory Complex.Researchers make choices in our work – informed by our discipline and our experience, we down-select, make judgments and assumptions, approximate, and ultimately press forward. Having a common goal ensures that the choices made by all of the talented researchers involved align together, and advance us on the path towards this achievement. It also ensures we are choosing the “right” science, especially when the science gets hard, and accelerates our progress.We draw inspiration from another aspect of the Manhattan Project as well. The Manhattan Project was successful in building the bomb and launched a far greater enterprise. It began the atomic era and spurred the many industries and applications that harness nuclear science, for both civilian and military benefit.Similarly, while our goal is nuclear proliferation detection, the potential for impact extends far beyond nuclear security. The challenges posed by the nuclear security domain are so demanding that, in building AI to detect nuclear proliferation, we believe we will advance the entire field.As we define the next generation of AI, we are sharing our insights broadly with others, through opportunities like AI workshops. We set the research direction for the broader community of AI researchers, like our partners in academia and basic research programs like the DOE Office of Science and the National Science Foundation, to build out the science of next-generation AI for nuclear and national security.Many nuclear proliferation detection technologies currently used by the United States monitor for the use of special nuclear material and equipment unique to nuclear weapons development. We are using AI to go after other indicators of weapons development, like research. These indicators are very hard to detect – in fact, it’s never been possible to develop technologies to detect them. AI gives us powerful new tools to do this. The AI-enabled technologies we are developing will broaden U.S. nuclear nonproliferation capability and afford us with more options for intervention and response to nuclear threats.For example, we are using AI to understand the relationships between research communities and to track nuclear-related research around the globe. You can’t just type in “nuclear weapons-usable research” into Google Scholar. And not all nuclear research will help you learn how to build a bomb. It takes a nuclear weapons expert to see the difference and a multidisciplinary team to develop AI systems that can see it too.We are also developing the capability to build AI systems that learn from multiple sources of data, from computational models, and from nuclear weapons experts. In one project, we apply these methods to analyze intelligence provided by multiple agencies to produce evidence of illicit procurement by foreign companies trafficking nuclear weapons-usable equipment and material. We are working closely with partners across the U.S. government to implement these capabilities to support operational interdiction missions.Right now, we’re making progress in building capabilities to use AI to address nuclear security challenges. But we are only one part of the picture. The future will see next-generation AI technologies elevated to the center of national decision making to inform operations and strategic policy. NNSA – and our country – need strategic leaders with the technical expertise, domain knowledge, and policymaking skills to lead the transformation of the Nuclear Security Enterprise with AI.To everyone, but especially to young women in science, I say: Be bold. You are brilliant and your ideas are clever. We need you to express them and make sure you are heard – your ideas will transform the world.The data show that our environments fail to be inclusive of women: they are discouraged from speaking up and there is a bias against listening to them. Women in STEM know from experience that the data does not lie.There is a phrase we often say in the National Laboratory Complex: “I know I’m not the smartest in the room…” I said that too when I first began as a researcher at PNNL. I sat in rooms full of other people who I considered the smartest in there, and someone would drop an intense science question or an unanswered national security challenge into the middle of this room full of very smart people. And no one would budge. No one would jump on it. No one shared ideas on how to address it. After watching that happen for a while and waiting for the “smarter” people to jump on the problem and lead the rest of us to a solution, I started to do it myself. I still felt like an imposter, and I was still intimidated, but I had an idea and a strategy to get it done. And none of the people I was intimidated by were trying.I have a bias for action in my strategy for AI and my approach to inclusive diversity. Everyone can encourage diversity and inclusion – not just in spirit, but also in action and as part of their everyday work.For example, we commit to balanced gender representation in our AI workshops, across all different parts of the team. Researchers and managers at every level can commit to including women and underrepresented groups in STEM at balanced rates that match the demographics of the United States. Opportunities include project teams, focus groups, interview panels, review boards, seminars and brown bags with invited speakers, and external conferences.When you can’t think of someone to include from an underrepresented group in a particular area of STEM, ask a colleague for a recommendation. Broaden the pool of candidates and expand your network so you are ready for the next opportunity to be inclusive.Working moms during the pandemic.I am a musician! I began training as a violinist, pianist, and vocalist at a very young age – today, I mostly sing and play piano for fun. There are a handful of us from DNN’s R&D team that formed a little band and performed at our office’s holiday parties before the pandemic, and we hope to do so again. As part of the campaign to push next-generation AI, Sheffield is leading a number of enterprise-wide , with partners from industry and academia contributing their knowledge as well. Keep an eye out for more of her work later this year, and learn more about DNN’s nonproliferation mission .  