 How can we make high performance computers operate as well as possible to accelerate scientific research?While I didn’t start my research with that question in mind, that’s where the freedom of the national laboratories has allowed it to go. I started at the U.S. Department of Energy’s (DOE) Argonne National Laboratory in 1982. At the time, I was looking at automated reasoning, an early form of artificial intelligence. However, I became bewitched by the potential of — by what at the time were — very high speed networks and parallel computers.Since then, I’ve devoted my career to developing technologies that help us get the most out of our high performance computers. I’ve collaborated with brilliant scientists to develop new ways to run their research. With grid computing, we’ve been able to connect computers together to share resources, making the network stronger than the sum of its parts. Parallel processing allows us to split apart complex simulations like climate models and run them on separate processors. This approach drastically speeds up these simulations, some of which wouldn’t be possible to run otherwise. Systems that can process outputs from X-ray light sources almost immediately allow scientists to know how good their data is. With this information, they can switch samples or revise the tool’s settings as needed.Without support from the DOE Office of Science’s Advanced Scientific Computing Research Program, many of these innovations wouldn’t be possible. I applaud their good taste in both the research that they support and their sustained commitment to computation for discovery.Computing is once again at a very exciting time. From artificial intelligence to exascale computers that can make a quadrillion calculations per second, we need to rethink what computing means for science.With this fellowship, I plan to pursue how computing can enable connections at the speed of thought. There are three areas that I think hold particular promise: autonomous experiments, neural networks for simulations, and technologies to tackle the data deluge.Computers act as cognitive prostheses. They can take on the monotonous aspects of science to let us have more time to think about the bigger issues. Although I started college as a chemistry major, I quit because of my lack of skill and interest in titrating solutions. I understand how mind-numbingly routine much of experimental science can be. An autonomous laboratory powered by artificial intelligence could run these types of experiments.In addition to being virtual hands, computers can also act as virtual brains. Fusion, materials, and other types of simulations are getting ever more complex. At the same time, there are physical limitations on how many more bits we can fit into a computer. Neural networks, where computers are structured to “think” like biological brains, offer a path forward.  Rather than scientists needing to hand-craft each estimate that goes into simulations, neural networks could minimize that work.As technologies evolve, the amount of data they produce grows exponentially. Argonne’s Advanced Photon Source will soon generate three orders of magnitude more data than before. Finding new ways to collect, process, and compare data to simulations will help scientists make the most of their observations.I look forward to engaging the community so we can rethink how computers can transform the scientific process in the 21 century. 