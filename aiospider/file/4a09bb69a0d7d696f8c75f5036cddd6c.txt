Credit: As part of Harvard Kennedy School’s Belfer Center for Science and International Affairs’ new  (TAPP) project, I am spending the 2020-21 academic year assessing risks to civil liberties posed by “smart city” technologies and developing recommended interventions. As part of this research, I will be regularly blogging updates on my thinking and overall project progress, as well as soliciting input. With this first post, I hope to introduce myself, describe the impetus for the project, and describe the evolving goals of the research. The background that I’ll bring to bear on this research is legal and city planning training, practitioner experience supporting a variety of city management subjects such as energy policy, affordable housing, and code enforcement, and 7 years of experience as an advocate, consultant, and civil servant developing various government data and IT policies (including many related to open access). My time spent  of  (an organization dedicated to collaborative and participatory community tools) and participating in DIY hackathons will also surely serve this research as a reminder of what is possible with technology development via grassroots efforts.The original inspiration for this research came from observing the thoughtful pushback by local  and  to Sidewalk Labs’ flagship “smart city” project in Toronto and wanting to support it further. Prior to , my primary concern with “smart city” products had been that vendors may be pitching technological solutions to complex civic problems that would ultimately under-deliver at the expense of the taxpayer. Sidewalk Toronto’s proposal however replaced concerns over “What if vendors can’t do what they claim?” with “What if they can?” Sidewalk Toronto’s proposal boasted an unprecedented number of data gathering tools and its parent company, Alphabet Inc., holds arguably one of the largest databases of personally identifiable information that has ever existed. This big data capacity, coupled with the proposal’s large corporate footprint on a public square, raised new and urgent concerns of surveillance, equity, and democracy. While Sidewalk Labs was pitching “one of the world’s first smart cities” in Toronto, law enforcement agencies in the United States were under increased scrutiny for using new and invasive facial recognition technology without privacy protections or oversight mechanisms in place and some local city councils had begun to ban the use of the technology outright. A contribution to this policymaking was surely Georgetown Law’s , which provided a comprehensive analysis of department’s related policies (or lack thereof) and a set of recommendations. I saw the need for a similar analysis and set of recommendations for new and invasive “smart city” technologies like those pitched by Sidewalk Toronto and submitted the research proposal to the TAPP team.Since originally pitching this research in January, global events and many conversations have helped me to refine my goals of the project, which will likely continue to be refined as I go. The potential and panic of COVID-19 contract tracing apps have raised new questions and examples of what acceptable surveillance looks like, while  have served as a reminder of how needed and at risk our right to protest freely is. One example of a risk to protest pertinent to this research was when . This example made it clear, that while my intent was not to focus on the tech used by law enforcement agencies (there is already great work being done in this area) that I would have to examine all “smart city” tech as potentially being used by law enforcement in my examination of risks. Shortly thereafter San Diego paused use of their street light cameras until privacy concerns were addressed and since my proposal pitch, Sidewalk Labs has backed out of Toronto. In addition to Sidewalk Toronto and San Diego, I have had conversations with experts and activists on other “smart city” projects that have received scrutiny, such as: , the , the , and examined related , and . I’ve also begun to examine suggested interventions such as  and . These conversations and examples have helped me refine the goals of this research to focus less on the specific regulation of any one specific “smart city” technology (the way the Perpetual Line Up had done with facial recognition technology), but instead to focus on larger power structures in play with (1) a “Follow the Money” approach to how these technologies are being funded and procured (e.g. Public-Private Partnerships, Federal Grants, vendor business-models) to examine their tensions with the public interest (2) a risk-framework that outlines harms that any one or collection of these technologies may create (e.g. discriminatory application, chilled freedom of assembly, corporate influence on the public spaces). The goals of this research are to:If you have examples of any of the above or suggestions for where I should dig further, please do not hesitate to be in touch:  